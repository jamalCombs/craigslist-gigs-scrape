{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60243b89-e5ba-4e0d-967e-51abf70a07c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3aba06-9769-4c11-a991-c91bf7851a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding module to the system path\n",
    "sys.path.append('..')\n",
    "from craiglist_gig_scraper import CraiglistGigScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315513b9-2d4c-4677-96da-e7774ab2359c",
   "metadata": {},
   "source": [
    "## Problem\n",
    "The task is to scrape the gigs section of Craigslist Boston and figure out how much money someone could make per day if they did all the gigs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd4f077-2eed-4495-a8c3-4095151b9ba6",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "1. Click on the 'paid' filter and 'bundle duplicates' checkbox to reduce noise in data\n",
    "2. Create a list of all the posts urls\n",
    "3. Open each url and for each post extract date, title, compensation, and type\n",
    "4. Store scrape date in a dataframe with columns (title, timestamp(date), compensation, type)\n",
    "5. Preform groupby sum aggregation on date and compensation to determine compensation per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37944307-88cb-45f4-b1a1-53d9d81108d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://boston.craigslist.org/search/gbs/ggg'\n",
    "scraper_one = CraiglistGigScraper()\n",
    "scraper_one.load_craigslist_url(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047cdb30-6c9e-471a-8a53-330d4a62c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all gig links\n",
    "links = scraper_one.extract_gig_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25303766-a46e-4f2d-8755-5291ff4bf385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_scrape(links, filename, action=''):\n",
    "    '''\n",
    "    Implements binary protocols for serializing and de-serializing objects\n",
    "    :param links: List\n",
    "    :param filename: String\n",
    "    :param action: String\n",
    "    '''\n",
    "    match action:\n",
    "        case 'dump':\n",
    "            with open(f'{filename}.pkl', 'wb') as file:\n",
    "                return pickle.dump(links, file)\n",
    "        case 'load':\n",
    "            with open(f'{filename}.pkl', 'rb') as file:\n",
    "                return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab45b92-2555-45a0-b080-8991f177e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_links = list(set(links))[:20]; cleaned_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0fec4-c8ee-4d25-9fc5-15d5e8822236",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Collect\n",
    "Gather data from Craiglist Gig section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac1997-c07b-4a7c-b635-f5e4258ad7a2",
   "metadata": {},
   "source": [
    "#### Step 1A: Launching parallel tasks\n",
    "Use ThreadPoolExecutor to asynchronously execute scrape class method.\n",
    "\n",
    "* CPU times: user 20.5 s, sys: 15.7 s, total: 36.2 s\n",
    "* Wall time: 28min 40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49aad1-82f4-4c1e-934a-3f529ce70a03",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for link in cleaned_links:\n",
    "        # submit fn schedules the callable and returns a future object representing the execution of the callable\n",
    "        futures.append(executor.submit(scraper_one.extract_gig_information, url=link))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7cc39-afd9-40d1-86bb-45083e53f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comp to unpack values returned by the call\n",
    "gigs = [future.result() for future in concurrent.futures.as_completed(futures)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc511a9-eea1-42d5-b7ed-2f691c98c548",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gig_df = pd.DataFrame(gigs, columns=['title', 'timestamp', 'compensation', 'type']); gig_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5d7d8-a094-4649-8f76-3122b10661d6",
   "metadata": {},
   "source": [
    "### Step 2: Clean\n",
    "Use Pandas and Python string manipulation to format text and number in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613630f-e5d4-4d75-929f-f9c1aa29fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gig_df = pd.read_csv('./data/gig_data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164b81e-24a1-4991-a2d3-5453c995fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_numbers(string):\n",
    "    '''Returns a boolean value if string is not a numeric'''\n",
    "    return any(char.isdigit() for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d870199-031e-4fff-9a1c-e34f55a0444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date and time columns from timestamp\n",
    "gig_df['time'] = gig_df['timestamp'].apply(lambda x: x.split('T')[0])\n",
    "# gig_df['date'] = gig_df['timestamp'].apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff0d34-7756-411c-833f-eaa5f60c2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp column to datetime\n",
    "gig_df['timestamp'] =  pd.to_datetime(gig_df['timestamp'])\n",
    "\n",
    "# Create day of week column based on timestamp\n",
    "gig_df['day_of_week'] = gig_df['timestamp'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d21d20-ea5c-4513-8503-dd3cd6ecd86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out strings that don't has a float or integer value\n",
    "gig_df['has_compensation'] = gig_df['compensation'].apply(lambda x: has_numbers(x))\n",
    "\n",
    "# Drop rows that don't have a numeric value\n",
    "gig_df.drop(gig_df[gig_df.has_compensation == False].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c3413-ec05-410c-910d-c75f6740a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply regex pattern to extract values with '$'\n",
    "gig_df['compensation'] = gig_df['compensation'].str.extract('(\\$[0-9,.]+)', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c8a27c-ddf3-477a-95e9-0f189a4cb191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and format compensation value\n",
    "gig_df = gig_df[gig_df['compensation'].notna()];\n",
    "gig_df['compensation'] = gig_df['compensation'].replace({'\\$':'', ',': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b75e4-10c9-4773-a4fa-f36796658587",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gig_df['compensation'] = gig_df['compensation'].apply(lambda x: int(float(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda664d-e6ab-47bd-a450-105dae3e9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check gigs over a thousand\n",
    "over_a_thousand = gig_df[gig_df['compensation'] >= 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd985c-5610-4b42-8756-583d13b4feed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out gigs greater than or equal to 5k\n",
    "filtered_gigs = gig_df[gig_df['compensation'] <= 5000]; filtered_gigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e351e255-1e54-46e1-aee6-71f6e8d9260d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sum of compensation\n",
    "aggregated_df = filtered_gigs.groupby(['date'], as_index=False)['compensation'].sum()\n",
    "aggregated_df = aggregated_df.rename(columns={'compensation': 'sum'})\n",
    "\n",
    "# Average of compensation\n",
    "aggregated_df['sum'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967042e4-8371-4ee4-ad39-2fba55455e78",
   "metadata": {},
   "source": [
    "### Step 3: Visualize\n",
    "Use Matiplotlib to visualize data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971182b-93c8-496f-a949-de35cb10d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "filtered_gigs.groupby(['type']).sum().plot(kind='pie', y='compensation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bde0aa-bd12-4797-8752-66671b38943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart\n",
    "plt.bar(filtered_gigs.date, filtered_gigs.compensation)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c66c6-6154-4903-bd8a-70b773176c50",
   "metadata": {},
   "source": [
    "### Step 4: Takeaways\n",
    "Discuss valuable takeaways and potential next steps\n",
    "\n",
    "1. Challenging data source \n",
    "    - What is the persona?\n",
    "    - How might someone ingest this data?\n",
    "2. Not representative sample because the paid filter returns gigs that don't mention any monetary value\n",
    "3. Assumptions\n",
    "    - How much time does this person have to work?\n",
    "    - Their distance relative to the gig location\n",
    "    - The type of gig they are most interested in\n",
    "    - The amount of jobs someone can complete\n",
    "    - The persons mode of transportation -- job requirements\n",
    "    - Gig duration\n",
    "4. Constraints \n",
    "    - CPU\n",
    "    - Time\n",
    "5. Decisions\n",
    "    - Drop non-numeric compensation values\n",
    "    - Filter out greater 5k\n",
    "    - Extract compensation values with'$'\n",
    "6. Issues with compensation values\n",
    "    - Project-based\n",
    "    - Salary\n",
    "    - Per hour\n",
    "7. Working with compensation values\n",
    "    - Apply ML (NLP)\n",
    "    - Pull in external APIs (Google Maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc4176-56ca-496d-9621-08f308e4b15c",
   "metadata": {},
   "source": [
    "### Tests\n",
    "Try out somethings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab8818-75ab-41ea-8dea-139d872a3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if a pattern or regex is contained within a string of a Series or Index.\n",
    "keyword_search_for = ['per', 'hour', 'hr']\n",
    "gig_df[gig_df.stack().str.contains('|'.join(keyword_search_for)).any(level=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969e996-2b6a-4172-9626-de4007a5ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting frequency counts of a column values\n",
    "count = gig_df['compensation'].value_counts(); count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca7618a-93bd-47e4-912b-496c2ce06507",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency = gig_df['compensation'].str.split(expand=True).stack().value_counts() \n",
    "pd.DataFrame(word_frequency, columns=['frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e02fa4-0ea9-4725-a057-d1d17e523870",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strings_list = ['compensation: $18-$24', 'compensation: $75 to $150 Daily']\n",
    "regex_split = [re.split('; |, |\\*|\\n|to|-|:| ', _str) for _str in test_strings_list]; regex_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three",
   "language": "python",
   "name": "three"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
